\label{chapter:resultados}

Este capítulo tem como objetivo apresentar o planejamento, execução e análise dos resultados obtidos a partir implementação do método proposto no sistema Hand.io. Esta avaliação teve como foco funcionamento do protótipo da luva por meio de um experimento em um cenário real levando em consideração a eficácia e a eficiência do sistema em situações de utilização nominal.

\section{Análise da implementação}

Nesta seção é detalhado e analisado de maneira extensiva as particularidades da implementação da Hand.io, tanto no projeto do \textit{hardware} quanto de \textit{software}.
% 
% \subsection{Análise do protótipo}
% 
Como havia sido definido anteriormente no método proposto no \autoref{chapter:metodo}, o protótipo da Hand.io consiste em duas partes, a luva de captura de movimentos e a central de processamento de sinais que controla de dispositivos que serão analisados de forma individual.

\subsection{Protótipo da luva de captura de movimentos}

A luva é composta por três principais componentes: 
(1) microcontrolador Arduino UNO, que decodifica os sinais do sensor e os envia pela porta serial conectada à central de processamento; 
(2) um sensor MPU $6050$ que conta com um acelerômetro e um giroscópio, utilizado para realizar a leitura dos movimentos; e 
(3) um botão, que é acionado pelo usuário para definir o início e o fim da captura dos movimentos. Os três componentes podem ser vistos na \autoref{fig:luva}.

\begin{figure}[ht]
    \centering
    \hfill
    \begin{subfigure}[b]{0.4\textwidth}
      \includegraphics[width=\textwidth]{resources/luva1.png}
    \end{subfigure}
    \hfill
    \begin{subfigure}[b]{0.4\textwidth}
      \includegraphics[width=\textwidth]{resources/luva2.png}
    \end{subfigure}
    \hfill
    \caption{Componentes da luva}
    \label{fig:luva}
\end{figure}

% Os componentes estão posicionados de maneira a garantir o máximo de conforto possível ao usuário. 
% É recomendada a utilização de 
Neste prototiopo foi adotado uma luva de pano para reduzir o contato do Arduino com a pele.
% , pois os pontos de solda no verso da placa podem criar eventuais escoriações com a utilização prolongada do sistema. 
O Arduino foi posicionado no dorso da mão, preso com fitas elásticas firmes para evitar movimentações indesejadas que levariam à uma leitura imprecisa dos movimentos.
% 
O sensor MPU $6050$ está fixado em uma \textit{mini protoboard} presa no topo do Arduino com fitas adesivas de maneira estável. O botão de acionamento de captura de movimentos conta com os seus fios trançados afim aumentar a rigidez da construção do protótipo. Ao final da trança os fios são ligados ao botão de modo a formar um anel em volta do dedo indicador do usuário. Este posicionamento visa aumentar a ergonomia da luva, pois o botão estará convenientemente localizado no alcance do polegar do operador.

\subsection{Protótipo da central de processamento de sinais}

O esquemático da central apresentado na \autoref{fig:esq_central} do \autoref{chapter:metodo} define que a central é composta por um computador de propósito geral equipado com um microprocessador, capaz de executar algoritmos de aprendizado de máquina e enviar e receber sinais infravermelhos. Componentes com as mesmas funcionalidades dos propostos anteriormente foram utilizados no protótipo final, de maneira que foi possível validar o método proposto sem que fossem realizadas mudanças significativas.

O protótipo da central exibido abaixo na \autoref{fig:central}, é composto por um Notebook\todo{Apresentar configurações}, conectado à luva através de uma conexão serial via cabo por uma porta USB, que processa os sinais recebidos e executa as ações correspondentes. Através de uma outra porta USB do Notebook, uma outra conexão serial ligada à um segundo Arduino UNO, que atua como atuador, é realizada. Este Arduino faz o papel de receptor e emissor de sinais infravermelhos para o controle de dispositivos no ambiente. 
% É recomendado que o atuador fique em um lugar próximo aos dispositivos que se deseja controlar devido ao alcance limitado do emissor de infravermelho.

\begin{figure}[ht]
    \centering
    \begin{center}
        \missingfigure[figwidth=10cm]{Imagem da central}
    \end{center}
    \caption{Central de controle}
    \label{fig:central}
\end{figure}


\subsection{Análise do código-fonte do protótipo}

Existem três algoritmos sendo executados simultaneamente de maneira independente no protótipo. Um algoritmo no Arduino acoplado à luva, um no Arduino conectado à central e um na central. Os códigos-fonte estão disponíveis no repositório online GitHub \url{https://github.com/JohnPinto/Hand.io}.

\subsubsection{Análise dos algoritmos dos Arduinos}

\todo[inline]{Se for focar nos algoritmos, vc deverá apresentar o pseudocodigo e as complexidades. Sugiro modificar para código}

Os algoritmos em execução nos dois Arduinos funcionam de maneira distinta. Durante a modelagem do sistema, foi definido que o Arduino presente na luva funcionaria apenas como sensor, enviando os sinais dos movimentos para a central, e o encontrado na central serviria de atuador, enviando os sinais infravermelhos para os dispositivos a serem controlados.

Durante o funcionamento nominal do sistema o Arduíno embutido na luva lê os sinais do sensor em tempo real, mas enquanto o botão de captura de movimentos presente na luva não for pressionado pelo usuário, é enviado para a central apenas uma sequência de pontos (\texttt{.}) com um curtíssimo intervalo de tempo entre os envios\todo{Qual o objetivo da seq. de pontos???}. 

Quando o botão é pressionado, a luva passa a enviar, pela porta serial, o sinal do acelerômetro e do giroscópio formatado  seguindo o padrão \texttt{\$    ax    ay    az    gx    gy    gz    $\setminus n$} terminado com uma quebra de linha, onde as componentes \texttt{x, y} e \texttt{z} dos sensores são indicadas pela letra \texttt{a} para acelerômetro e \texttt{g} para giroscópio, o \texttt{\$}, indica o início da leitura e a quebra de linha o fim. 

% O sinal é enviado desta maneira afim de garantir a consistência da transmissão dos dados. 
O comportamento de envio do sinal intercalado de pontos (\texttt{.}) e sinais serve de condição de parada do algoritmo da central que será detalhado nas seções a seguir. Foi utilizada a biblioteca \textit{SoftwareSerial}\footnote{\url{https://www.arduino.cc/en/Reference/SoftwareSerial}\label{ftnote:serial}} para a realização de comunicação serial.

O Arduino conectado à central que serve de atuador, permanece ocioso até que um comando indicando qual sinal infravermelho deverá ser enviado seja recebido. Os códigos infravermelhos ficam armazenados diretamente no Arduino, graças ao desacoplamento dos códigos da memória RAM para a flash\footnote{\url{https://www.arduino.cc/reference/en/language/variables/utilities/progmem/}}, isto permite ao usuário realizar o cadastro de centenas de códigos infravermelhos de dispositivos diferentes. 

Devido à natureza estacionária da central, é possível que múltiplos atuadores estejam inseridos em diversos cômodos diferentes de uma casa, por exemplo, o que serviria de aplicação para este trabalho. Na implementação deste algoritmo foram utilizadas as biblioteca SoftwareSerial\textsuperscript{\ref{ftnote:serial}}, para comunicação serial, e IRremote\footnote{\url{https://github.com/z3t0/Arduino-IRremote}}, para envio de sinais infravermelhos a partir do Arduino.


\subsubsection{Análise dos algoritmos da central}


O algoritmo aplicado na central de processamento tem a implementação detalhada na \autoref{fig:class}, onde é apresentado o diagrama de classes que define as especificidades do sistema e detalha as relações entre as classes que compõem o constituem.

\begin{figure}[ht]
    \centering
    \includegraphics[width=\textwidth, keepaspectratio]{resources/diagrama_classe.pdf}
    \caption{Diagrama de classe da Hand.io}
    \label{fig:class}
\end{figure}

O código-fonte foi desenvolvido na linguagem de programação Python $3$, utilizando conceitos de programação orientada a objetos, como classes e herança, visando compartimentalizar o código com o objetivo de aumentar a previsibilidade, e evitar retrabalhos por parte do desenvolvedor. 

A linguagem em questão foi escolhida por sua praticidade de implementação graças à sua natureza de alto nível, o que permite uma implementação rápida e simples em comparação com as demais linguagens. Outro grande fator motivador é a presença de uma vasta gama de bibliotecas externas que agilizaram grandemente o desenvolvimento do protótipo, como o Scikit-learn\footnote{\url{https://scikit-learn.org/}\label{ftnote:sklearn}} e a PySerial\footnote{\url{https://github.com/pyserial/pyserial}\label{ftnote:pyserial}}\todo{Descrever qual o objetivo destas libs.}.

No diagrama de classes abaixo a \textit{HandIO} é a classe principal do sistema. Esta classe conta com definições de sensor, atuador e classificador. Ambos os sensores e atuadores, implementados nas classes de nomes correspondentes, herdam da classe abstrata \textit{SerialObject}, com a diferença de que o sensor tem a capacidade de enviar sinais e o atuador apenas de recebe-los. Internamente a classe \textit{SerialObject} utiliza a biblioteca PySerial\textsuperscript{\ref{ftnote:pyserial}}, para a transmissão de dados. 

Já o classificador, implementado na classe \textit{Classifier}, utiliza usa a biblioteca Scikit-learn\textsuperscript{\ref{ftnote:sklearn}}, que conta com uma série de algoritmos de aprendizado de máquina já implementados com uma \textit{API} de utilização bastante simplificada. Os \textit{datasets} utilizados como parâmetro para a classificação dos gestos ficam armazenados na pasta \textit{datasets/} do sistema. 

A geração destes dados se dá utilizando o método \textit{record()} da classe \textit{HandIO}, que pede que o usuário insira uma classe, que define qual gesto será registrado, e realize 10 gestos, este procedimento é repetido até que o usuário pare o programa. Para o protótipo foi levantado um \textit{dataset} com 240 leituras recolhidas de seis usuários diferentes, distribuídas entre quatro classes de gestos correspondentes à movimentos nas direções: cima, baixo, direita e esquerda.

\todo[inline]{Terminar parte de crossvalidação}

A definição de qual algoritmo seria mais preciso para a classificação dos gestos foi realizada utilizando \textit{cross-validation}

A classe HandIO conta com diversos dicionários que agem como um especie de banco de dados do sistema, esta abordagem foi escolhida para que haja a possibilidade do usuário modificar ou adicionar novos gestos ou dispositivos de maneira simplificada. Todos os dicionários utilizados são carregados a partir de seus arquivos \textit{.json} correspondentes que podem ser encontrados na pasta \textit{json/} da raiz do sistema. Foram implementados métodos privados que iniciam com a palavra \textit{load}, que carregam cada dicionário individualmente, estes métodos são chamados no construtor do objeto.

\newpage

\subsection{Fluxo de execução}

\begin{figure}[ht]
    \centering
    \includegraphics[width=\textwidth, keepaspectratio]{resources/maquina_estados.pdf}
    \caption{Máquina de estados da Hand.io}
    \label{fig:automato}
\end{figure}

O sistema conta com duas grandes fases apresentadas na máquina de estados da \autoref{fig:automato}. A fase de seleção de dispositivo, definida na parte superior da figura, e a fase de seleção de ação, na parte inferior. O fluxo de execução será abordado do ponto de vista da máquina de estados, realizando anotações sobre quais métodos das classes, expostos na \autoref{fig:class}, são chamados durante um dado estado. 

Na classe \textit{HandIO} está implementado o método público \textit{init()}, que é responsável pelo funcionamento nominal da central. Os procedimentos dentro deste método, refletem o comportamento definido na máquina de estados apresentada anteriormente.

Durante os estágios iniciais da primeira e da segunda fase, os estados \textbf{ws} e \textbf{w.}, que foram implementados no método \textit{waitSignal()}, o sistema fica aguardando os sinais de início e parada de captura de movimentos. Em um primeiro momento que forem recebidos pontos pela serial, a central permanece no estado \textbf{ws}, ao ser constatado o recebimento de um sinal de movimento, o sistema passará para o estado \textbf{w.}.

O algoritmo permanecerá neste estado até que voltem a ser recebidos pontos, para que então o ultimo sinal recebido seja salvo no atributo \textit{data}, e enviado para o classificador no estado \textbf{clf} que chama o método \textit{classify()}. Após o retorno da classificação, o sistema passará para o estado \textbf{dict}, onde os resultados serão avaliados.

Neste estado o resultado da classificação serve como entrada para o método \textit{chooseDevice()} ou para o método \textit{chooseAction()}, dependendo da fase que o programa se encontra. Nestes métodos o resultado é utilizado como chave no dicionario \textit{commands} que retorna o dispositivo ou ação correspondente ao gesto. 
Caso o dicionário retorne um sinal válido o sistema então passa para o estado \textbf{sound}, que chama o método \textit{soundSignal()} caso o retorno seja inválido o sistema retornará ao estado inicial. Durante a segunda fase do algoritmo os possíveis retornos do dicionário ficam restritos às possíveis ações que dispositivo previamente selecionado tem mapeados pelo sistema. 

O estado \textbf{command}, implementado no método \textit{sendCommand()}, analisa a ação selecionada no estado anterior e as realiza no dispositivo selecionado. Ao final das duas fases o sistema entra no estado \textbf{clear}, que limpa a seleção de dispositivo e gesto, para que um novo comando seja realizado. 

\section{Planejamento e projeto do cenário experimental}

Um cenário experimental foi criado para avaliar a capacidade da Hand.io de controlar dispositivos em um ambiente real a partir das leituras de sensores, será utilizado nesta avaliação o protótipo discutido na seção anterior deste capítulo. Como referência do progresso do experimento, as questões avaliativas levantadas abaixo serão respondidas conforme o andamento dos experimentos:

\begin{description}
    \item \label{qa:1} \textbf{QA1:} Um usuário que recebeu instruções simples de utilização da luva, consegue controlar os dispositivos do ambiente sem maiores dificuldades? 
    \item  \label{qa:2} \textbf{QA2:} Qual a taxa de sucesso do sistema para detectar os gestos corretamente e enviar sinais aos dispositivos correspondentes?
    \item \label{qa:3} \textbf{QA3:} 
\end{description}

\subsection{Preparação do cenário}

O ambiente no qual o cenário se dará conta com, um ar-condicionado, do fabricante Carrier, uma TV Philips e uma apresentação de slides que ocorre no \textit{notebook}, que servirá de central de processamento de dados, e será exibida na TV. Para controle de dispositivos que contam com uma interface de controle por meio de sinais infravermelhos, como é o caso do ar-condicionado e da TV selecionas, é necessário que os sinais enviados pelos controles remotos destes dispositivos sejam capturados e carregados no Arduino que serve como atuador. Para controle da apresentação de slides, não é necessária intervenção por parte do instalador do sistema, pois o sistema já conta com as funcionalidades para este tipo de operação.

\begin{figure}[ht]
    \centering
    \begin{center}
        \missingfigure[figwidth=10cm]{Cenário experimental}
    \end{center}
    \caption{Cenário experimental}
    \label{fig:central}
\end{figure}

\subsection{Preparação do experimento}

\section{Execução do cenário experimental e análise dos resultados}

